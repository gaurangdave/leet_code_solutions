{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "adb78719",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4e5b9392",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n"
     ]
    }
   ],
   "source": [
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cf3dccf",
   "metadata": {},
   "source": [
    "# Problem #1: Generating a Normalized Coordinate Grid\n",
    "**Source** : Gemini\n",
    "\n",
    "**Context**\n",
    "In many computer vision tasks, particularly in object detection (e.g., YOLO, SSD), we divide an image into a grid. Each cell in this grid is responsible for predicting objects located within it. To do this, the model needs to know the location of each grid cell. Your task is to generate a tensor that contains the normalized (x, y) coordinates of the center of each cell.\n",
    "\n",
    "**Your Task**\n",
    "Write a Python function generate_normalized_grid(grid_size) that takes an integer grid_size and returns a TensorFlow tensor with the following properties:\n",
    "\n",
    "**Shape**: (grid_size, grid_size, 2)\n",
    "\n",
    "**Data Type**: tf.float32\n",
    "\n",
    "**Content**: The tensor should represent a grid where the last dimension [..., 0] holds the normalized x-coordinates and [..., 1] holds the normalized y-coordinates. The coordinates must be normalized to the range [0.0, 1.0).\n",
    "\n",
    "**Normalization Logic**: For a grid of size N, the center of the cell at (row, col) has coordinates ((col + 0.5) / N, (row + 0.5) / N).\n",
    "\n",
    "**Example**\n",
    "If grid_size = 2, the expected output tensor is:\n",
    "```python\n",
    "<tf.Tensor: shape=(2, 2, 2), dtype=float32, numpy=\n",
    "[[[0.25, 0.25],  # Cell at (row=0, col=0) -> (x=0.25, y=0.25)\n",
    "  [0.75, 0.25]], # Cell at (row=0, col=1) -> (x=0.75, y=0.25)\n",
    "\n",
    " [[0.25, 0.75],  # Cell at (row=1, col=0) -> (x=0.25, y=0.75)\n",
    "  [0.75, 0.75]]]># Cell at (row=1, col=1) -> (x=0.75, y=0.75)\n",
    "```\n",
    "Notice how the x-coordinate increases along the columns and the y-coordinate increases along the rows.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5c3a040",
   "metadata": {},
   "source": [
    "## Thoughts\n",
    "* So here we need a vectorized solution that creates a tensor whose values depend on its indices.\n",
    "* I think it would help to initialize the grid cells with index values. \n",
    "* We can initialize the grid with zeroes and then use `scatter_nd_update` to update the row cells and column cells.\n",
    "\n",
    "### Update\n",
    "* Found a simpler way to do this, created 2 colums using tf.range and tf.repeat and combined it to create a tensor grid where each cell value represented its coordinate value.\n",
    "* After that calculation was as simple as broadcasting addition and division \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e26d845",
   "metadata": {},
   "source": [
    "## Solution 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0a06aa7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def generate_normalized_grid(grid_size = 2):\n",
    "    ## step 1 - get the grid indices range\n",
    "    grid_range = tf.range(grid_size, dtype=tf.float32)\n",
    "    ## create column 0 for the grid - this column represents the x-coordinate of each grid cell\n",
    "    ## value indices of this column would be 0,0,1,1 for grid_size 2\n",
    "    col_0 = tf.reshape(tf.repeat(grid_range,repeats=grid_size), shape=(grid_size,grid_size,1))\n",
    "    ## create column 1 for the grid - this column represents y-coordinate of each cell\n",
    "    col_1 = tf.reshape(tf.repeat([grid_range],repeats=grid_size,axis=0),shape=(grid_size,grid_size,1))\n",
    "    ## concatenate to form our grid\n",
    "    ## currently each grid cell represents it index value in float. \n",
    "    grid = tf.concat(values = [col_1,col_0], axis = 2)\n",
    "    ## calculate the grid cell center. \n",
    "    coordinate_grid = (grid + 0.5)/grid_size\n",
    "    return coordinate_grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b46b7212",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 2, 2), dtype=float32, numpy=\n",
       "array([[[0.25, 0.25],\n",
       "        [0.75, 0.25]],\n",
       "\n",
       "       [[0.25, 0.75],\n",
       "        [0.75, 0.75]]], dtype=float32)>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_normalized_grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a1de84a",
   "metadata": {},
   "source": [
    "## Solution 2 - using tf.meshgrid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d734b08f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def generate_grid_cooridinates(grid_size = 2):\n",
    "    # 1. Create a 1D vector for x indices: [0, 1, 2, ...]\n",
    "    coorinate_range = tf.range(grid_size, dtype=tf.float32)\n",
    "    grid_X,grid_Y = tf.meshgrid(coorinate_range,coorinate_range)\n",
    "    coordinate_grid = tf.stack(values=[grid_X,grid_Y], axis=2)\n",
    "    return coordinate_grid\n",
    "    \n",
    "def generate_normalized_grid(grid_size = 2):\n",
    "    coordinate_grid = generate_grid_cooridinates(grid_size=grid_size)\n",
    "    normalized_grid = (coordinate_grid + 0.5) / grid_size\n",
    "    return normalized_grid\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6cc9b977",
   "metadata": {},
   "outputs": [],
   "source": [
    "normalized_grid = generate_normalized_grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b50a6684",
   "metadata": {},
   "source": [
    "# Problem #2 : Scaling the Grid to Image Coordinates\n",
    "**Source**: Gemini\n",
    "\n",
    "**Context**\n",
    "In our object detection project, the normalized grid you just created is a generic, resolution-independent representation. However, to actually use it with a specific image, we need to convert those [0.0, 1.0) coordinates into actual pixel coordinates. For example, the center of the top-left cell in a 13x13 grid might be (0.038, 0.038) in normalized space, but on a 416x416 pixel image, that corresponds to pixel (16, 16).\n",
    "\n",
    "**Your Task**\n",
    "Write a Python function `scale_grid_to_pixels(normalized_grid, image_shape)` that takes two arguments:\n",
    "\n",
    "**normalized_grid**: The output tensor from our previous problem, with shape (grid_size, grid_size, 2).\n",
    "\n",
    "**image_shape**: A 1D TensorFlow tensor or a Python tuple/list of two integers, **`[height, width]`**.\n",
    "\n",
    "The function should return a new tensor with the same shape as normalized_grid, but where the (x, y) coordinates have been scaled to the pixel space of the image.\n",
    "\n",
    "**Scaling Logic**:\n",
    "\n",
    "`pixel_x = normalized_x * width`\n",
    "\n",
    "`pixel_y = normalized_y * height`\n",
    "\n",
    "**Example**:\n",
    "Given the normalized_grid for grid_size = 2:\n",
    "```\n",
    "[[[0.25, 0.25], [0.75, 0.25]],\n",
    " [[0.25, 0.75], [0.75, 0.75]]]\n",
    "```\n",
    "And an image_shape of [416, 416], the expected output is:\n",
    "```\n",
    "<tf.Tensor: shape=(2, 2, 2), dtype=float32, numpy=\n",
    "[[[104., 104.],  # (0.25*416, 0.25*416)\n",
    "  [312., 104.]], # (0.75*416, 0.25*416)\n",
    "\n",
    " [[104., 312.],  # (0.25*416, 0.75*416)\n",
    "  [312., 312.]]]># (0.75*416, 0.75*416)\n",
    "```\n",
    "**Important**: Note the order. The image_shape is (height, width), but our coordinate grid is (x, y). Your solution will need to handle this correctly."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "285f5633",
   "metadata": {},
   "source": [
    "## Thoughts\n",
    "* First impression of this problem is that this is straight forward, just a simple multiplication. Lets try that and see"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e69a4055",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def scale_grid_to_pixels(normalized_grid, image_shape):\n",
    "    ## cast to float32\n",
    "    img_shape_float = tf.cast(image_shape, dtype=tf.float32)\n",
    "    ## reorder the image shape colums so that we multiply normalized_x with width and normalized_y with height\n",
    "    reordered_column = tf.gather(params=img_shape_float, indices=[1,0],axis=0)\n",
    "    scaled_grid = tf.multiply(normalized_grid, reordered_column)\n",
    "    return scaled_grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "35a0d2fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 2, 2), dtype=float32, numpy=\n",
       "array([[[104., 104.],\n",
       "        [312., 104.]],\n",
       "\n",
       "       [[104., 312.],\n",
       "        [312., 312.]]], dtype=float32)>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_shape = tf.constant(value=[416,416])\n",
    "scale_grid_to_pixels(normalized_grid=normalized_grid,image_shape=image_shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e439e0b",
   "metadata": {},
   "source": [
    "# Problem #3: Batch-Scaling Grids for Multiple Images\n",
    "\n",
    "**Context**\n",
    "To train a neural network efficiently, we process multiple images at once in a \"batch\". Our grid scaling logic needs to support this. We'll have one common normalized_grid, but a list of different image shapes—one for each image in the batch. Your task is to perform the scaling operation for the entire batch in a single, vectorized call.\n",
    "\n",
    "**Your Task**\n",
    "Write a function batch_scale_grids(normalized_grid, batch_image_shapes) that takes:\n",
    "\n",
    "`normalized_grid: The (grid_size, grid_size, 2) tensor from Problem #1.`\n",
    "\n",
    "`batch_image_shapes: A 2D tensor of shape (batch_size, 2), where each row is an [height, width] pair.`\n",
    "\n",
    "The function should return a single tensor of shape (batch_size, grid_size, grid_size, 2) containing the scaled grid for each image.\n",
    "\n",
    "**Example**\n",
    "Given normalized_grid (for grid_size=2) and batch_image_shapes:\n",
    "\n",
    "```python\n",
    "# A batch of 2 images with different shapes\n",
    "batch_image_shapes = tf.constant([[416, 416],  # Image 1 is 416x416\n",
    "                                  [800, 600]], # Image 2 is 800x600 (WxH) -> No, (HxW)\n",
    "                                 dtype=tf.int32)\n",
    "```\n",
    "The goal is to multiply the single (2, 2, 2) normalized grid with the (2, 2) batch of shapes to produce a (2, 2, 2, 2) - (batch_size, grid_size, grid_size, 2) output tensor."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7509d2b9",
   "metadata": {},
   "source": [
    "## Thoughts\n",
    "* This is interesting, the shape of both these tensors are different, so direct tensor multiplication won't work. \n",
    "* We can try and use `tf.newaxis` to add axis to normalized grid and then do a tf.reshape to get the desired output. \n",
    "* We'll also need to reorder elements of batch image shape like we did before. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "edab5da3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_normalized_grid(normalized_grid, batch_image_shapes):\n",
    "    batch_image_shapes_float = tf.cast(batch_image_shapes, dtype=tf.float32)\n",
    "    ## reorder the values\n",
    "    batch_image_shapes_float_reordered = tf.reverse(batch_image_shapes_float, axis=[-1])\n",
    "    ## add additional axis\n",
    "    batch_image_shapes_float_reordered = batch_image_shapes_float_reordered[:,tf.newaxis,tf.newaxis,:]\n",
    "    normalized_grid_expanded = normalized_grid[tf.newaxis,:]\n",
    "    ## this will give us batch_image_shape as (batch_size,1,1,2) and normalized grid as (1,grid_size,grid_size,2)\n",
    "    ## multiplying these two will give us (batch_size, grid_size,grid_size,2)\n",
    "    normalized_grid = tf.multiply(normalized_grid_expanded,batch_image_shapes_float_reordered)\n",
    "    return normalized_grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c0debd92",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_image_shapes = tf.constant([[416, 416],  # Image 1 is 416x416\n",
    "                                  [800, 600]], # Image 2 is 800x600 (WxH) -> No, (HxW)\n",
    "                                 dtype=tf.int32)\n",
    "\n",
    "normalized_grids = batch_normalized_grid(normalized_grid=normalized_grid, batch_image_shapes=batch_image_shapes)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a19d668b",
   "metadata": {},
   "source": [
    "# Problem #4: Generating Anchor Box Grids\n",
    "\n",
    "## **Context**\n",
    "\n",
    "So far, we have the coordinates for the *center* of each grid cell. In modern object detectors (like YOLO), each grid cell doesn't just predict one object; it's responsible for several \"anchor boxes\" of different pre-defined shapes and sizes (e.g., a tall box, a wide box, a large square box). The model's job isn't to predict a box from scratch, but rather to predict small *adjustments* to the closest matching anchor box.\n",
    "\n",
    "Our task is to generate the full set of anchor boxes for every grid cell across every image in our batch.\n",
    "\n",
    "## **Your Task**\n",
    "\n",
    "Write a function `generate_anchor_grids(scaled_grids, anchor_boxes)` that takes:\n",
    "\n",
    "1.  `scaled_grids`: The output from our previous problem—a tensor of pixel coordinates for the grid centers, with shape `(batch_size, grid_size, grid_size, 2)`.\n",
    "2.  `anchor_boxes`: A 2D tensor of shape `(num_anchors, 2)`, where each row is a `[width, height]` pair for a pre-defined anchor.\n",
    "\n",
    "The function should return a tensor of shape `(batch_size, grid_size, grid_size, num_anchors, 4)`. This final tensor represents the specific bounding boxes (in `[x_min, y_min, x_max, y_max]` format) for every anchor at every grid location.\n",
    "\n",
    "**Calculation Logic**:\n",
    "For each grid center `(cx, cy)` from `scaled_grids` and each anchor size `(w, h)` from `anchor_boxes`:\n",
    "* `x_min = cx - w / 2`\n",
    "* `y_min = cy - h / 2`\n",
    "* `x_max = cx + w / 2`\n",
    "* `y_max = cy + h / 2`\n",
    "\n",
    "**Core Challenge**: This is another broadcasting puzzle, but with more dimensions. You'll need to expand both `scaled_grids` and `anchor_boxes` so you can perform the `center +/- size/2` calculation. After calculating the `min` and `max` coordinates, you will need to combine them to form the final `(..., 4)` dimension.\n",
    "\n",
    "This is the most complex problem yet, but it uses the exact same principles you've already mastered. Good luck!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2ae967c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def generate_anchor_grids(scaled_grids, anchor_boxes):\n",
    "    ## step 1: add axis to scaled grids\n",
    "    reshaped_scaled_grids = scaled_grids[:,:,:,tf.newaxis,:]\n",
    "    ## step 2: add axis to anchor_boxes\n",
    "    reshaped_anchor_boxes = anchor_boxes[tf.newaxis,tf.newaxis,tf.newaxis,:,:]\n",
    "    ## step 3: calculate min values\n",
    "    min_values = reshaped_scaled_grids - reshaped_anchor_boxes/2\n",
    "    max_values = reshaped_scaled_grids + reshaped_anchor_boxes/2\n",
    "    ## step 4: calculate anchor grid\n",
    "    anchor_grid = tf.concat([min_values,max_values],axis=-1)\n",
    "    return anchor_grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "1e62ee31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 2, 2, 3, 4), dtype=float32, numpy=\n",
       "array([[[[[ 95.,  95., 105., 105.],\n",
       "          [ 90.,  95., 110., 105.],\n",
       "          [ 95.,  90., 105., 110.]],\n",
       "\n",
       "         [[295.,  95., 305., 105.],\n",
       "          [290.,  95., 310., 105.],\n",
       "          [295.,  90., 305., 110.]]],\n",
       "\n",
       "\n",
       "        [[[ 95., 295., 105., 305.],\n",
       "          [ 90., 295., 110., 305.],\n",
       "          [ 95., 290., 105., 310.]],\n",
       "\n",
       "         [[295., 295., 305., 305.],\n",
       "          [290., 295., 310., 305.],\n",
       "          [295., 290., 305., 310.]]]]], dtype=float32)>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Shape: (batch_size=1, grid_size=2, grid_size=2, 2)\n",
    "## i.e. one 2x2 grid => 4 grid centers. \n",
    "scaled_grids = tf.constant(\n",
    "    [[[[100., 100.], [300., 100.]],\n",
    "      [[100., 300.], [300., 300.]]]],\n",
    "    dtype=tf.float32\n",
    ")\n",
    "\n",
    "# Shape: (num_anchors=3, 2)\n",
    "# i.e. 3 anchors defined with their width and height.\n",
    "anchor_boxes = tf.constant(\n",
    "    [[10., 10.],  # Anchor 1: width=10, height=10\n",
    "     [20., 10.],  # Anchor 2: width=20, height=10\n",
    "     [10., 20.]], # Anchor 3: width=10, height=20\n",
    "    dtype=tf.float32\n",
    ")\n",
    "\n",
    "anchor_grid = generate_anchor_grids(scaled_grids=scaled_grids,anchor_boxes=anchor_boxes)\n",
    "anchor_grid\n",
    "  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "0791741e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([ 90.  95. 110. 105.], shape=(4,), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "print(anchor_grid[0, 0, 0, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef41efae",
   "metadata": {},
   "source": [
    "# Problem #5: Calculating Intersection over Union (IoU)\n",
    "\n",
    "## **Context**\n",
    "\n",
    "Intersection over Union (IoU) is a number from 0 to 1 that measures how much two bounding boxes overlap. It's the ratio of the area of their intersection to the area of their union.\n",
    "\n",
    "IoU is critical for two main reasons:\n",
    "\n",
    "1.  **During Training**: We use IoU to match our generated anchor boxes to the ground truth object boxes. An anchor with a high IoU to a ground truth box is considered a \"positive\" example responsible for predicting that object.\n",
    "2.  **During Inference**: We use IoU in a process called Non-Max Suppression (NMS) to eliminate redundant, overlapping predictions for the same object.\n",
    "\n",
    "Your task is to implement a fully vectorized function that calculates the pairwise IoU for two sets of boxes.\n",
    "\n",
    "## **Your Task**\n",
    "\n",
    "Write a function `calculate_iou(boxes1, boxes2)` that takes:\n",
    "\n",
    "1.  `boxes1`: A tensor of shape `(N, 4)` representing N bounding boxes.\n",
    "2.  `boxes2`: A tensor of shape `(M, 4)` representing M bounding boxes.\n",
    "\n",
    "<!-- end list -->\n",
    "\n",
    "  * The box format for both is `[x_min, y_min, x_max, y_max]`.\n",
    "\n",
    "The function should return a 2D tensor of shape `(N, M)`, where `output[i, j]` is the IoU score between `boxes1[i]` and `boxes2[j]`.\n",
    "\n",
    "## **Calculation Logic**\n",
    "\n",
    "This is a multi-step calculation that will require broadcasting to compare every box from `boxes1` with every box from `boxes2`.\n",
    "\n",
    "1.  **Expand Dims for Broadcasting**: Reshape `boxes1` to `(N, 1, 4)` and `boxes2` to `(1, M, 4)`.\n",
    "2.  **Find Intersection Coordinates**:\n",
    "      * The top-left corner of the intersection is `(max(box1_x_min, box2_x_min), max(box1_y_min, box2_y_min))`. Use `tf.maximum`.\n",
    "      * The bottom-right corner is `(min(box1_x_max, box2_x_max), min(box1_y_max, box2_y_max))`. Use `tf.minimum`.\n",
    "3.  **Calculate Intersection Area**:\n",
    "      * Calculate the width and height of the intersection.\n",
    "      * **Crucial Edge Case**: If the boxes don't overlap, the width or height can be negative. You must clip them at 0 (`tf.maximum(width, 0)`). The area is then `width * height`.\n",
    "4.  **Calculate Union Area**:\n",
    "      * Calculate the area of all boxes in `boxes1` and `boxes2`. Area is `(x_max - x_min) * (y_max - y_min)`.\n",
    "      * The union area is `area1 + area2 - intersection_area`.\n",
    "5.  **Calculate IoU**:\n",
    "      * `IoU = intersection_area / union_area`.\n",
    "      * **Crucial Edge Case**: To avoid dividing by zero if the union area is 0, add a tiny number (epsilon, e.g., `1e-7`) to the denominator.\n",
    "\n",
    "-----\n",
    "\n",
    "### Test Data\n",
    "\n",
    "```python\n",
    "# boxes1 has 2 boxes\n",
    "boxes1 = tf.constant([[0, 0, 10, 10],   # Box A\n",
    "                       [15, 15, 25, 25]], # Box B\n",
    "                      dtype=tf.float32)\n",
    "\n",
    "# boxes2 has 3 boxes\n",
    "boxes2 = tf.constant([[5, 5, 15, 15],     # Box C (overlaps A)\n",
    "                       [0, 0, 10, 10],     # Box D (identical to A)\n",
    "                       [30, 30, 40, 40]],  # Box E (no overlap)\n",
    "                      dtype=tf.float32)\n",
    "```\n",
    "\n",
    "## **Expected Output Shape**: `(2, 3)`\n",
    "\n",
    "## **Sanity Check**\n",
    "\n",
    "  * **IoU of Box A and Box D**: They are identical. The intersection is the area of the box (100), and the union is also the area of the box (100). The IoU should be `1.0`.\n",
    "  * **IoU of Box B and Box E**: They have no overlap. The intersection area is 0. The IoU should be `0.0`.\n",
    "\n",
    "This one brings everything together: broadcasting, element-wise math, slicing, and handling edge cases. Good luck\\!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "9e0cadd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_iou(boxes1, boxes2):\n",
    "    # step 1 expand dimensions\n",
    "    reshaped_boxes1 = boxes1[:, tf.newaxis, :]\n",
    "    reshaped_boxes2 = boxes2[tf.newaxis, :, :]\n",
    "\n",
    "    # step 2 calculate top left corner of intersection\n",
    "    # top_left_x = tf.maximum(reshaped_boxes1[:, :, 0], reshaped_boxes2[:, :, 0])\n",
    "    # top_left_y = tf.maximum(reshaped_boxes1[:, :, 1], reshaped_boxes2[:, :, 1])\n",
    "    # top_left = tf.stack([top_left_x, top_left_y], axis=-1)\n",
    "    top_left = tf.maximum(reshaped_boxes1[:, :, 0:2],reshaped_boxes2[:, :, 0:2])\n",
    "    \n",
    "    # step 3 calculate bottom right corner of intersection\n",
    "    # bottom_right_x = tf.minimum(\n",
    "    #     reshaped_boxes1[:, :, 2], reshaped_boxes2[:, :, 2])\n",
    "    # bottom_right_y = tf.minimum(\n",
    "    #     reshaped_boxes1[:, :, 3], reshaped_boxes2[:, :, 3])\n",
    "    # bottom_right = tf.stack([bottom_right_x, bottom_right_y], axis=-1)\n",
    "    bottom_right = tf.minimum(reshaped_boxes1[:, :, 2:],reshaped_boxes2[:, :, 2:])\n",
    "\n",
    "    # step 4 calculate intersection area width\n",
    "    intersection_width = tf.maximum(\n",
    "        (bottom_right[:, :, 0] - top_left[:, :, 0]), 0)\n",
    "\n",
    "    # step 5 calculate intersection height\n",
    "    intersection_height = tf.maximum(\n",
    "        (bottom_right[:, :, 1] - top_left[:, :, 1]), 0)\n",
    "\n",
    "    # step 6 calculate intersection area\n",
    "    intersection_area = intersection_width * intersection_height\n",
    "\n",
    "    # step 7 calculate intersection union\n",
    "    boxes1_area = (reshaped_boxes1[:, :, 2] - reshaped_boxes1[:, :, 0]) * \\\n",
    "        (reshaped_boxes1[:, :, 3] - reshaped_boxes1[:, :, 1])\n",
    "        \n",
    "    boxes2_area = (reshaped_boxes2[:, :, 2] - reshaped_boxes2[:, :, 0]) * \\\n",
    "        (reshaped_boxes2[:, :, 3] - reshaped_boxes2[:, :, 1])        \n",
    "    \n",
    "    union_area = boxes1_area + boxes2_area - intersection_area\n",
    "\n",
    "    ## step 8 calculate iou\n",
    "    epsilon = 1e-7 ## adding epsilon to ensure that denominator is always non-zero.\n",
    "    iou = intersection_area / (union_area + epsilon)\n",
    "\n",
    "    return iou"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a57157c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 3), dtype=float32, numpy=\n",
       "array([[0.14285715, 1.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        ]], dtype=float32)>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# boxes1 has 2 boxes\n",
    "boxes1 = tf.constant([[0, 0, 10, 10],   # Box A\n",
    "                       [15, 15, 25, 25]], # Box B\n",
    "                      dtype=tf.float32)\n",
    "\n",
    "# boxes2 has 3 boxes\n",
    "boxes2 = tf.constant([[5, 5, 15, 15],     # Box C (overlaps A)\n",
    "                       [0, 0, 10, 10],     # Box D (identical to A)\n",
    "                       [30, 30, 40, 40]],  # Box E (no overlap)\n",
    "                      dtype=tf.float32)\n",
    "\n",
    "ious= calculate_iou(boxes1=boxes1,boxes2=boxes2)\n",
    "ious"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e0e6d6a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 2, 3)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 1, 3), dtype=int32, numpy=\n",
       "array([[[3, 3, 3]],\n",
       "\n",
       "       [[5, 5, 5]]], dtype=int32)>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = tf.constant([[[1, 1, 1], [2, 2, 2]],\n",
    "                 [[3, 3, 3], [4, 4, 4]],\n",
    "                 [[5, 5, 5], [6, 6, 6]]])\n",
    "\n",
    "print(t.shape)\n",
    "tf.slice(t, [1, 0, 0], [1, 1, 3])  # [[[3, 3, 3]]]\n",
    "tf.slice(t, [1, 0, 0], [1, 2, 3])  # [[[3, 3, 3],\n",
    "                                   #   [4, 4, 4]]]\n",
    "tf.slice(t, [1, 0, 0], [2, 1, 3])  # [[[3, 3, 3]],\n",
    "                                   #  [[5, 5, 5]]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8718239e",
   "metadata": {},
   "source": [
    "# Problem #6: Decoding Bounding Box Predictions\n",
    "\n",
    "## **Context**\n",
    "\n",
    "We've now created a comprehensive grid of anchor boxes. A model like YOLO or SSD doesn't learn to predict a box's final coordinates directly. Instead, it learns to predict four small adjustment values—`tx`, `ty`, `tw`, and `th`—relative to each anchor box. This makes the training process more stable.\n",
    "\n",
    "Our job is to take the model's raw output (`tx`, `ty`, `tw`, `th`) and apply it to our anchor boxes to get the final, human-readable bounding box coordinates. This process is called **decoding**.\n",
    "\n",
    "The standard formulas to do this are:\n",
    "\n",
    "  * `predicted_center_x = (tx * anchor_width) + anchor_center_x`\n",
    "  * `predicted_center_y = (ty * anchor_height) + anchor_center_y`\n",
    "  * `predicted_width = anchor_width * exp(tw)`\n",
    "  * `predicted_height = anchor_height * exp(th)`\n",
    "\n",
    "The use of `exp()` for the width and height ensures the final dimensions are always positive.\n",
    "\n",
    "## **Your Task**\n",
    "\n",
    "Write a function `decode_predictions(anchor_boxes, predictions)` that takes:\n",
    "\n",
    "1.  `anchor_boxes`: A tensor of anchor boxes, with shape `(B, G, G, A, 4)`, in the format `[x_min, y_min, x_max, y_max]`. `B` is batch size, `G` is grid size, `A` is number of anchors.\n",
    "2.  `predictions`: A tensor of the same shape, `(B, G, G, A, 4)`, containing the model's raw output `[tx, ty, tw, th]`.\n",
    "\n",
    "The function should return a tensor of the decoded boxes, also in `[x_min, y_min, x_max, y_max]` format and with the same shape `(B, G, G, A, 4)`.\n",
    "\n",
    "**The core challenge** in this problem is not broadcasting (the input shapes already match), but **coordinate format conversion**. The decoding formulas require the anchor box to be in `[center_x, center_y, width, height]` format, but the input and output need to be in `[x_min, y_min, x_max, y_max]` format. Your implementation will need to handle these conversions.\n",
    "\n",
    "-----\n",
    "\n",
    "### Test Data\n",
    "\n",
    "Let's use a very simple case with a batch of 1, a 1x1 grid, and 1 anchor.\n",
    "\n",
    "```python\n",
    "import tensorflow as tf\n",
    "\n",
    "# A single anchor box with shape (1, 1, 1, 1, 4)\n",
    "# Corresponds to cx=100, cy=100, w=20, h=10\n",
    "anchor_boxes = tf.constant([[[[90., 95., 110., 105.]]]], dtype=tf.float32)\n",
    "\n",
    "# The model's raw prediction for this anchor box\n",
    "predictions = tf.constant([[[[0.1, -0.2, 0.5, -0.5]]]], dtype=tf.float32)\n",
    "```\n",
    "\n",
    "#### **Sanity Check**\n",
    "\n",
    "With the inputs above, your function should produce a final decoded box of approximately `[85.51, 94.97, 118.49, 101.03]`.\n",
    "\n",
    "I'm ready for your solution\\!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "93c0e096",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_predictions(anchor_boxes, predictions):\n",
    "    ## step 1: calculate anchor box centers\n",
    "    anchor_box_centers = (anchor_boxes[...,0:2] + anchor_boxes[...,2:]) / 2\n",
    "    tf.print(\"shape of anchorbox centers\", tf.shape(anchor_box_centers))\n",
    "    ## step 2: calculate anchor box width & height\n",
    "    anchor_box_dimensions = anchor_boxes[...,2:] - anchor_boxes[...,0:2]\n",
    "    tf.print(\"shape of anchor_box_dimensions\", tf.shape(anchor_box_dimensions))\n",
    "    \n",
    "    ## step 3: decode predicted_center\n",
    "    predicted_center = (predictions[...,0:2] * anchor_box_dimensions[...,0:2]) + anchor_box_centers[...,0:2] \n",
    "    \n",
    "    ## step 4: decoded predicted_dimensions\n",
    "    predicted_dimensions = anchor_box_dimensions * tf.exp(predictions[...,2:])\n",
    "    \n",
    "    ## step 5: concat the decoded values    \n",
    "    combined_predictions = tf.concat([predicted_center,predicted_dimensions],axis=-1)\n",
    "    \n",
    "    ## step 6: convert the values to coordinates\n",
    "    decoded_min = ((2 * predicted_center[...,0:2]) - predicted_dimensions[...,0:])/2\n",
    "    decoded_max = ((2 * predicted_center[...,0:2]) + predicted_dimensions[...,0:])/2\n",
    "    tf.print(\"Shape of decoded_min:\", tf.shape(decoded_min))\n",
    "    tf.print(\"Shape of decoded_max:\", tf.shape(decoded_max))\n",
    "    \n",
    "    decoded_predictions = tf.concat([decoded_min,decoded_max], axis=-1)\n",
    "    \n",
    "    return decoded_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "38f676d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 1, 1, 1, 4)\n",
      "(1, 1, 1, 1, 4)\n",
      "shape of anchorbox centers [1 1 1 1 2]\n",
      "shape of anchor_box_dimensions [1 1 1 1 2]\n",
      "Shape of decoded_min: [1 1 1 1 2]\n",
      "Shape of decoded_max: [1 1 1 1 2]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 1, 1, 1, 4), dtype=float32, numpy=array([[[[[ 85.51279,  94.96735, 118.48721, 101.03265]]]]], dtype=float32)>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# A single anchor box with the CORRECT shape (1, 1, 1, 1, 4)\n",
    "anchor_boxes = tf.constant([[[[[90., 95., 110., 105.]]]]], dtype=tf.float32)\n",
    "\n",
    "# The model's raw prediction with the CORRECT shape (1, 1, 1, 1, 4)\n",
    "predictions = tf.constant([[[[[0.1, -0.2, 0.5, -0.5]]]]], dtype=tf.float32)\n",
    "\n",
    "print(anchor_boxes.shape)\n",
    "print(predictions.shape)\n",
    "\n",
    "decoded_predictions = decode_predictions(\n",
    "    anchor_boxes=anchor_boxes,\n",
    "    predictions=predictions\n",
    ")\n",
    "decoded_predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e530b6c3",
   "metadata": {},
   "source": [
    "# Problem #7: Filtering Predictions by Confidence Score\n",
    "\n",
    "## **Context**\n",
    "\n",
    "Our `decode_predictions` function produces thousands of potential bounding boxes. However, the vast majority of them are garbage—they don't contain any object. Along with the box coordinates `(tx, ty, tw, th)`, the model also predicts a **confidence score** (often called \"objectness\") for each box. This score, from 0 to 1, represents how sure the model is that an anchor box actually contains an object.\n",
    "\n",
    "The very first step in cleaning up the model's output is to throw away all the boxes with a low confidence score. This is a simple but powerful filter that drastically reduces the number of boxes we need to analyze in later steps.\n",
    "\n",
    "## **Your Task**\n",
    "\n",
    "Write a function `filter_by_confidence(decoded_boxes, confidence_scores, threshold)` that takes:\n",
    "\n",
    "1.  `decoded_boxes`: The tensor of decoded boxes from our previous problem, with shape `(B, G, G, A, 4)`.\n",
    "2.  `confidence_scores`: A tensor of confidence scores for each box, with shape `(B, G, G, A, 1)`.\n",
    "3.  `threshold`: A scalar float (e.g., `0.5`). Any box with a score below this threshold should be discarded.\n",
    "\n",
    "The function should return two tensors:\n",
    "\n",
    "1.  `filtered_boxes`: A 2D tensor of shape `(num_good_boxes, 4)` containing only the box coordinates that met the threshold.\n",
    "2.  `filtered_scores`: A 2D tensor of shape `(num_good_boxes, 1)` containing the corresponding scores.\n",
    "\n",
    "**Note:** `num_good_boxes` is the total number of boxes across the entire batch whose confidence score was `>= threshold`. The output tensors are \"flattened,\" containing all good boxes from all images in the batch.\n",
    "\n",
    "-----\n",
    "\n",
    "### Test Data\n",
    "\n",
    "Let's use a batch of 1, with a 1x2 grid and 2 anchors per cell (4 boxes total).\n",
    "\n",
    "```python\n",
    "import tensorflow as tf\n",
    "\n",
    "# Shape: (1, 1, 2, 2, 4)\n",
    "decoded_boxes = tf.constant(\n",
    "    [[[[[10, 10, 20, 20],   # Box 1\n",
    "        [12, 12, 22, 22]],  # Box 2\n",
    "       [[30, 30, 40, 40],   # Box 3\n",
    "        [32, 32, 42, 42]]]]],\n",
    "    dtype=tf.float32)\n",
    "\n",
    "# Shape: (1, 1, 2, 2, 1)\n",
    "confidence_scores = tf.constant(\n",
    "    [[[[[0.9],  # Score 1\n",
    "        [0.2]], # Score 2\n",
    "       [[0.7],  # Score 3\n",
    "        [0.1]]]]],\n",
    "    dtype=tf.float32)\n",
    "\n",
    "# A confidence threshold of 0.5\n",
    "threshold = 0.5\n",
    "```\n",
    "\n",
    "## **Sanity Check**\n",
    "\n",
    "With the data above, your function should keep Box 1 (score 0.9) and Box 3 (score 0.7). The expected outputs would be:\n",
    "\n",
    "  * `filtered_boxes` should have a shape of `(2, 4)`.\n",
    "  * `filtered_scores` should have a shape of `(2, 1)`.\n",
    "\n",
    "The core of this problem is figuring out how to use the result of a comparison on one tensor to select elements from another tensor. Ready when you are\\!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d761f816",
   "metadata": {},
   "source": [
    "### Solution 1 - Apply Mask Manually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "565c0235",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_by_confidence(decoded_boxes,confidence_scores,threshold):\n",
    "    ## step 1: calculate the mask\n",
    "    confidence_score_mask = confidence_scores >= threshold\n",
    "        \n",
    "    ## step 2: expand the mask to match decoded boxes shape\n",
    "    confidence_score_mask_repeated = tf.repeat(confidence_score_mask,repeats=4, axis=-1)\n",
    "\n",
    "    ## step 3: create indices for gather_nd\n",
    "    confidence_score_mask_indices = tf.where(confidence_score_mask_repeated)\n",
    "    \n",
    "    ## step 4: apply mask indices to read high score elements\n",
    "    filtered_boxes = tf.gather_nd(decoded_boxes,indices=confidence_score_mask_indices,batch_dims=0)\n",
    "    \n",
    "    ## step 5: reshape to expected output shape.\n",
    "    filtered_boxes = tf.reshape(filtered_boxes, shape=(-1,4))\n",
    "    \n",
    "    ## step 6: extract filtered scores the same way\n",
    "    confidence_score_mask_indices = tf.where(confidence_score_mask)\n",
    "    filtered_scores = tf.gather_nd(confidence_scores,indices=confidence_score_mask_indices,batch_dims=0)\n",
    "    filtered_scores = tf.reshape(filtered_scores, shape=(-1,1))\n",
    "    \n",
    "    return filtered_boxes,filtered_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "d5940a26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(2, 4), dtype=float32, numpy=\n",
       " array([[10., 10., 20., 20.],\n",
       "        [30., 30., 40., 40.]], dtype=float32)>,\n",
       " <tf.Tensor: shape=(2, 1), dtype=float32, numpy=\n",
       " array([[0.9],\n",
       "        [0.7]], dtype=float32)>)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Shape: (1, 1, 2, 2, 4)\n",
    "decoded_boxes = tf.constant(\n",
    "    [[[[[10, 10, 20, 20],   # Box 1\n",
    "        [12, 12, 22, 22]],  # Box 2\n",
    "       [[30, 30, 40, 40],   # Box 3\n",
    "        [32, 32, 42, 42]]]]],\n",
    "    dtype=tf.float32)\n",
    "\n",
    "# Shape: (1, 1, 2, 2, 1)\n",
    "confidence_scores = tf.constant(\n",
    "    [[[[[0.9],  # Score 1\n",
    "        [0.2]], # Score 2\n",
    "       [[0.7],  # Score 3\n",
    "        [0.1]]]]],\n",
    "    dtype=tf.float32)\n",
    "\n",
    "# A confidence threshold of 0.5\n",
    "threshold = 0.5\n",
    "\n",
    "filtered_boxes,filtered_scores = filter_by_confidence(decoded_boxes=decoded_boxes,confidence_scores=confidence_scores,threshold=threshold)\n",
    "filtered_boxes,filtered_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f49bf37",
   "metadata": {},
   "source": [
    "### Solution 2 - Using Boolean Mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "93f1f6ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_by_confidence(decoded_boxes,confidence_scores,threshold):    \n",
    "    ## step 1: calculate the mask\n",
    "    confidence_score_mask = confidence_scores >= threshold\n",
    "    \n",
    "     # Step 2: Remove the dimension with size 1\n",
    "    mask_4d = tf.squeeze(confidence_score_mask, axis=-1)\n",
    "    \n",
    "    \n",
    "    # 3. Apply the 4D mask to the 5D tensors.\n",
    "    filtered_boxes = tf.boolean_mask(decoded_boxes, mask_4d)\n",
    "    filtered_scores = tf.boolean_mask(confidence_scores, mask_4d)\n",
    "    \n",
    "    return filtered_boxes,filtered_scores\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "b13ffb95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(2, 4), dtype=float32, numpy=\n",
       " array([[10., 10., 20., 20.],\n",
       "        [30., 30., 40., 40.]], dtype=float32)>,\n",
       " <tf.Tensor: shape=(2, 1), dtype=float32, numpy=\n",
       " array([[0.9],\n",
       "        [0.7]], dtype=float32)>)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Shape: (1, 1, 2, 2, 4)\n",
    "decoded_boxes = tf.constant(\n",
    "    [[[[[10, 10, 20, 20],   # Box 1\n",
    "        [12, 12, 22, 22]],  # Box 2\n",
    "       [[30, 30, 40, 40],   # Box 3\n",
    "        [32, 32, 42, 42]]]]],\n",
    "    dtype=tf.float32)\n",
    "\n",
    "# Shape: (1, 1, 2, 2, 1)\n",
    "confidence_scores = tf.constant(\n",
    "    [[[[[0.9],  # Score 1\n",
    "        [0.2]], # Score 2\n",
    "       [[0.7],  # Score 3\n",
    "        [0.1]]]]],\n",
    "    dtype=tf.float32)\n",
    "\n",
    "# A confidence threshold of 0.5\n",
    "threshold = 0.5\n",
    "\n",
    "filtered_boxes,filtered_scores = filter_by_confidence(decoded_boxes=decoded_boxes,confidence_scores=confidence_scores,threshold=threshold)\n",
    "filtered_boxes,filtered_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f9eec58",
   "metadata": {},
   "source": [
    "# Problem #8: Non-Max Suppression (NMS)\n",
    "\n",
    "## **Context**\n",
    "\n",
    "After filtering for confidence, our model might still output multiple, highly confident, overlapping boxes for the same object. For example, when detecting a single cat, we might get three boxes that all look pretty good.\n",
    "\n",
    "We only want to keep the single *best* box and discard the redundant ones. The standard algorithm for this is called **Non-Max Suppression (NMS)**. The name sounds complex, but the idea is simple: for any group of overlapping boxes, find the one with the maximum confidence score and suppress (delete) the rest.\n",
    "\n",
    "The general logic is:\n",
    "\n",
    "1.  Select the box with the highest confidence score.\n",
    "2.  Compare it to all other boxes and discard any that have a high IoU with it.\n",
    "3.  Repeat with the next-highest-scoring box that hasn't been discarded.\n",
    "4.  Continue until all boxes are either selected or discarded.\n",
    "\n",
    "Implementing this efficiently with loops is tricky. As you'd expect, TensorFlow has a built-in, highly-optimized function for this common task. Your challenge is to find this function in the TensorFlow API and use it correctly.\n",
    "\n",
    "## **Your Task**\n",
    "\n",
    "Write a function `perform_nms(boxes, scores, max_output_boxes, iou_threshold)` that takes:\n",
    "\n",
    "1.  `boxes`: A 2D tensor of shape `(num_boxes, 4)` in the format `[y_min, x_min, y_max, x_max]`. **Note the `(y, x)` order, which is a common requirement for this operation in TensorFlow.**\n",
    "2.  `scores`: A 1D tensor of shape `(num_boxes,)` containing the confidence score for each box.\n",
    "3.  `max_output_boxes`: A scalar integer for the maximum number of boxes to select.\n",
    "4.  `iou_threshold`: A scalar float (e.g., 0.5). Boxes with an IoU above this threshold relative to a higher-scoring box will be suppressed.\n",
    "\n",
    "The function should return:\n",
    "\n",
    "1.  `selected_indices`: A 1D tensor of integers representing the indices of the boxes that were kept by the NMS algorithm.\n",
    "\n",
    "-----\n",
    "\n",
    "### Test Data\n",
    "\n",
    "Here are four boxes. Box A and Box B overlap significantly. Box C is nearby. Box D is far away.\n",
    "\n",
    "```python\n",
    "import tensorflow as tf\n",
    "\n",
    "# Note the [y_min, x_min, y_max, x_max] format\n",
    "boxes = tf.constant([[10, 10, 20, 20],  # Box A\n",
    "                     [11, 11, 21, 21],  # Box B (highly overlaps with A)\n",
    "                     [25, 25, 35, 35],  # Box C (separate)\n",
    "                     [100, 100, 110, 110]],# Box D (far away)\n",
    "                    dtype=tf.float32)\n",
    "\n",
    "# Scores for each box\n",
    "scores = tf.constant([0.8, 0.9, 0.75, 0.6], dtype=tf.float32)\n",
    "\n",
    "# Parameters for NMS\n",
    "max_output_boxes = 10\n",
    "iou_threshold = 0.5\n",
    "```\n",
    "\n",
    "## **Sanity Check**\n",
    "\n",
    "The NMS algorithm should perform the following logic:\n",
    "\n",
    "1.  Select Box B (score 0.9), as it has the highest score.\n",
    "2.  Suppress Box A because its IoU with Box B is very high (well above 0.5).\n",
    "3.  Select Box C (score 0.75), the next highest scorer. Its IoU with Box B is 0.\n",
    "4.  Select Box D (score 0.6). Its IoU with both B and C is 0.\n",
    "\n",
    "The indices of the original boxes are `0, 1, 2, 3`. The final selected indices should correspond to Box B, Box C, and Box D. Therefore, the expected output is a tensor containing the indices `[1, 2, 3]`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2d5ff92",
   "metadata": {},
   "outputs": [],
   "source": [
    "def perform_nms(boxes, scores, max_output_boxes, iou_threshold):\n",
    "    nm_indices = tf.image.non_max_suppression(boxes,scores,max_output_boxes,iou_threshold)\n",
    "    return nm_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "9c76cc68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3,), dtype=int32, numpy=array([1, 2, 3], dtype=int32)>"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Note the [y_min, x_min, y_max, x_max] format\n",
    "boxes = tf.constant([[10, 10, 20, 20],  # Box A\n",
    "                     [11, 11, 21, 21],  # Box B (highly overlaps with A)\n",
    "                     [25, 25, 35, 35],  # Box C (separate)\n",
    "                     [100, 100, 110, 110]],# Box D (far away)\n",
    "                    dtype=tf.float32)\n",
    "\n",
    "# Scores for each box\n",
    "scores = tf.constant([0.8, 0.9, 0.75, 0.6], dtype=tf.float32)\n",
    "\n",
    "# Parameters for NMS\n",
    "max_output_boxes = 10\n",
    "iou_threshold = 0.5\n",
    "\n",
    "nms_output = perform_nms(boxes=boxes,scores=scores,max_output_boxes=max_output_boxes,iou_threshold=iou_threshold)\n",
    "nms_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "904f72ec",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
