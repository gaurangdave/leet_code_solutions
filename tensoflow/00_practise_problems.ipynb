{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "adb78719",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-12 13:21:25.817887: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4e5b9392",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n"
     ]
    }
   ],
   "source": [
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cf3dccf",
   "metadata": {},
   "source": [
    "# Problem #1: Generating a Normalized Coordinate Grid\n",
    "**Source** : Gemini\n",
    "\n",
    "**Context**\n",
    "In many computer vision tasks, particularly in object detection (e.g., YOLO, SSD), we divide an image into a grid. Each cell in this grid is responsible for predicting objects located within it. To do this, the model needs to know the location of each grid cell. Your task is to generate a tensor that contains the normalized (x, y) coordinates of the center of each cell.\n",
    "\n",
    "**Your Task**\n",
    "Write a Python function generate_normalized_grid(grid_size) that takes an integer grid_size and returns a TensorFlow tensor with the following properties:\n",
    "\n",
    "**Shape**: (grid_size, grid_size, 2)\n",
    "\n",
    "**Data Type**: tf.float32\n",
    "\n",
    "**Content**: The tensor should represent a grid where the last dimension [..., 0] holds the normalized x-coordinates and [..., 1] holds the normalized y-coordinates. The coordinates must be normalized to the range [0.0, 1.0).\n",
    "\n",
    "**Normalization Logic**: For a grid of size N, the center of the cell at (row, col) has coordinates ((col + 0.5) / N, (row + 0.5) / N).\n",
    "\n",
    "**Example**\n",
    "If grid_size = 2, the expected output tensor is:\n",
    "```python\n",
    "<tf.Tensor: shape=(2, 2, 2), dtype=float32, numpy=\n",
    "[[[0.25, 0.25],  # Cell at (row=0, col=0) -> (x=0.25, y=0.25)\n",
    "  [0.75, 0.25]], # Cell at (row=0, col=1) -> (x=0.75, y=0.25)\n",
    "\n",
    " [[0.25, 0.75],  # Cell at (row=1, col=0) -> (x=0.25, y=0.75)\n",
    "  [0.75, 0.75]]]># Cell at (row=1, col=1) -> (x=0.75, y=0.75)\n",
    "```\n",
    "Notice how the x-coordinate increases along the columns and the y-coordinate increases along the rows.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5c3a040",
   "metadata": {},
   "source": [
    "## Thoughts\n",
    "* So here we need a vectorized solution that creates a tensor whose values depend on its indices.\n",
    "* I think it would help to initialize the grid cells with index values. \n",
    "* We can initialize the grid with zeroes and then use `scatter_nd_update` to update the row cells and column cells.\n",
    "\n",
    "### Update\n",
    "* Found a simpler way to do this, created 2 colums using tf.range and tf.repeat and combined it to create a tensor grid where each cell value represented its coordinate value.\n",
    "* After that calculation was as simple as broadcasting addition and division \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e26d845",
   "metadata": {},
   "source": [
    "## Solution 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0a06aa7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def generate_normalized_grid(grid_size = 2):\n",
    "    ## step 1 - get the grid indices range\n",
    "    grid_range = tf.range(grid_size, dtype=tf.float32)\n",
    "    ## create column 0 for the grid - this column represents the x-coordinate of each grid cell\n",
    "    ## value indices of this column would be 0,0,1,1 for grid_size 2\n",
    "    col_0 = tf.reshape(tf.repeat(grid_range,repeats=grid_size), shape=(grid_size,grid_size,1))\n",
    "    ## create column 1 for the grid - this column represents y-coordinate of each cell\n",
    "    col_1 = tf.reshape(tf.repeat([grid_range],repeats=grid_size,axis=0),shape=(grid_size,grid_size,1))\n",
    "    ## concatenate to form our grid\n",
    "    ## currently each grid cell represents it index value in float. \n",
    "    grid = tf.concat(values = [col_1,col_0], axis = 2)\n",
    "    ## calculate the grid cell center. \n",
    "    coordinate_grid = (grid + 0.5)/grid_size\n",
    "    return coordinate_grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b46b7212",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1760300491.093246   63937 gpu_device.cc:2020] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 6053 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 2080 SUPER, pci bus id: 0000:2d:00.0, compute capability: 7.5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 2, 2), dtype=float32, numpy=\n",
       "array([[[0.25, 0.25],\n",
       "        [0.75, 0.25]],\n",
       "\n",
       "       [[0.25, 0.75],\n",
       "        [0.75, 0.75]]], dtype=float32)>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_normalized_grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a1de84a",
   "metadata": {},
   "source": [
    "## Solution 2 - using tf.meshgrid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d734b08f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def generate_grid_cooridinates(grid_size = 2):\n",
    "    # 1. Create a 1D vector for x indices: [0, 1, 2, ...]\n",
    "    coorinate_range = tf.range(grid_size, dtype=tf.float32)\n",
    "    grid_X,grid_Y = tf.meshgrid(coorinate_range,coorinate_range)\n",
    "    coordinate_grid = tf.stack(values=[grid_X,grid_Y], axis=2)\n",
    "    return coordinate_grid\n",
    "    \n",
    "def generate_normalized_grid(grid_size = 2):\n",
    "    coordinate_grid = generate_grid_cooridinates(grid_size=grid_size)\n",
    "    normalized_grid = (coordinate_grid + 0.5) / grid_size\n",
    "    return normalized_grid\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6cc9b977",
   "metadata": {},
   "outputs": [],
   "source": [
    "normalized_grid = generate_normalized_grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b50a6684",
   "metadata": {},
   "source": [
    "# Problem #2 : Scaling the Grid to Image Coordinates\n",
    "**Source**: Gemini\n",
    "\n",
    "**Context**\n",
    "In our object detection project, the normalized grid you just created is a generic, resolution-independent representation. However, to actually use it with a specific image, we need to convert those [0.0, 1.0) coordinates into actual pixel coordinates. For example, the center of the top-left cell in a 13x13 grid might be (0.038, 0.038) in normalized space, but on a 416x416 pixel image, that corresponds to pixel (16, 16).\n",
    "\n",
    "**Your Task**\n",
    "Write a Python function `scale_grid_to_pixels(normalized_grid, image_shape)` that takes two arguments:\n",
    "\n",
    "**normalized_grid**: The output tensor from our previous problem, with shape (grid_size, grid_size, 2).\n",
    "\n",
    "**image_shape**: A 1D TensorFlow tensor or a Python tuple/list of two integers, **`[height, width]`**.\n",
    "\n",
    "The function should return a new tensor with the same shape as normalized_grid, but where the (x, y) coordinates have been scaled to the pixel space of the image.\n",
    "\n",
    "**Scaling Logic**:\n",
    "\n",
    "`pixel_x = normalized_x * width`\n",
    "\n",
    "`pixel_y = normalized_y * height`\n",
    "\n",
    "**Example**:\n",
    "Given the normalized_grid for grid_size = 2:\n",
    "```\n",
    "[[[0.25, 0.25], [0.75, 0.25]],\n",
    " [[0.25, 0.75], [0.75, 0.75]]]\n",
    "```\n",
    "And an image_shape of [416, 416], the expected output is:\n",
    "```\n",
    "<tf.Tensor: shape=(2, 2, 2), dtype=float32, numpy=\n",
    "[[[104., 104.],  # (0.25*416, 0.25*416)\n",
    "  [312., 104.]], # (0.75*416, 0.25*416)\n",
    "\n",
    " [[104., 312.],  # (0.25*416, 0.75*416)\n",
    "  [312., 312.]]]># (0.75*416, 0.75*416)\n",
    "```\n",
    "**Important**: Note the order. The image_shape is (height, width), but our coordinate grid is (x, y). Your solution will need to handle this correctly."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "285f5633",
   "metadata": {},
   "source": [
    "## Thoughts\n",
    "* First impression of this problem is that this is straight forward, just a simple multiplication. Lets try that and see"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e69a4055",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def scale_grid_to_pixels(normalized_grid, image_shape):\n",
    "    ## cast to float32\n",
    "    img_shape_float = tf.cast(image_shape, dtype=tf.float32)\n",
    "    ## reorder the image shape colums so that we multiply normalized_x with width and normalized_y with height\n",
    "    reordered_column = tf.gather(params=img_shape_float, indices=[1,0],axis=0)\n",
    "    scaled_grid = tf.multiply(normalized_grid, reordered_column)\n",
    "    return scaled_grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "35a0d2fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 2, 2), dtype=float32, numpy=\n",
       "array([[[104., 104.],\n",
       "        [312., 104.]],\n",
       "\n",
       "       [[104., 312.],\n",
       "        [312., 312.]]], dtype=float32)>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_shape = tf.constant(value=[416,416])\n",
    "scale_grid_to_pixels(normalized_grid=normalized_grid,image_shape=image_shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e439e0b",
   "metadata": {},
   "source": [
    "# Problem #3: Batch-Scaling Grids for Multiple Images\n",
    "\n",
    "**Context**\n",
    "To train a neural network efficiently, we process multiple images at once in a \"batch\". Our grid scaling logic needs to support this. We'll have one common normalized_grid, but a list of different image shapes—one for each image in the batch. Your task is to perform the scaling operation for the entire batch in a single, vectorized call.\n",
    "\n",
    "**Your Task**\n",
    "Write a function batch_scale_grids(normalized_grid, batch_image_shapes) that takes:\n",
    "\n",
    "`normalized_grid: The (grid_size, grid_size, 2) tensor from Problem #1.`\n",
    "\n",
    "`batch_image_shapes: A 2D tensor of shape (batch_size, 2), where each row is an [height, width] pair.`\n",
    "\n",
    "The function should return a single tensor of shape (batch_size, grid_size, grid_size, 2) containing the scaled grid for each image.\n",
    "\n",
    "**Example**\n",
    "Given normalized_grid (for grid_size=2) and batch_image_shapes:\n",
    "\n",
    "```python\n",
    "# A batch of 2 images with different shapes\n",
    "batch_image_shapes = tf.constant([[416, 416],  # Image 1 is 416x416\n",
    "                                  [800, 600]], # Image 2 is 800x600 (WxH) -> No, (HxW)\n",
    "                                 dtype=tf.int32)\n",
    "```\n",
    "The goal is to multiply the single (2, 2, 2) normalized grid with the (2, 2) batch of shapes to produce a (2, 2, 2, 2) - (batch_size, grid_size, grid_size, 2) output tensor."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7509d2b9",
   "metadata": {},
   "source": [
    "## Thoughts\n",
    "* This is interesting, the shape of both these tensors are different, so direct tensor multiplication won't work. \n",
    "* We can try and use `tf.newaxis` to add axis to normalized grid and then do a tf.reshape to get the desired output. \n",
    "* We'll also need to reorder elements of batch image shape like we did before. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "edab5da3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_normalized_grid(normalized_grid, batch_image_shapes):\n",
    "    batch_image_shapes_float = tf.cast(batch_image_shapes, dtype=tf.float32)\n",
    "    ## reorder the values\n",
    "    batch_image_shapes_float_reordered = tf.reverse(batch_image_shapes_float, axis=[-1])\n",
    "    ## add additional axis\n",
    "    batch_image_shapes_float_reordered = batch_image_shapes_float_reordered[:,tf.newaxis,tf.newaxis,:]\n",
    "    normalized_grid_expanded = normalized_grid[tf.newaxis,:]\n",
    "    ## this will give us batch_image_shape as (batch_size,1,1,2) and normalized grid as (1,grid_size,grid_size,2)\n",
    "    ## multiplying these two will give us (batch_size, grid_size,grid_size,2)\n",
    "    normalized_grid = tf.multiply(normalized_grid_expanded,batch_image_shapes_float_reordered)\n",
    "    return normalized_grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c0debd92",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_image_shapes = tf.constant([[416, 416],  # Image 1 is 416x416\n",
    "                                  [800, 600]], # Image 2 is 800x600 (WxH) -> No, (HxW)\n",
    "                                 dtype=tf.int32)\n",
    "\n",
    "normalized_grids = batch_normalized_grid(normalized_grid=normalized_grid, batch_image_shapes=batch_image_shapes)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a19d668b",
   "metadata": {},
   "source": [
    "# Problem #4: Generating Anchor Box Grids\n",
    "\n",
    "## **Context**\n",
    "\n",
    "So far, we have the coordinates for the *center* of each grid cell. In modern object detectors (like YOLO), each grid cell doesn't just predict one object; it's responsible for several \"anchor boxes\" of different pre-defined shapes and sizes (e.g., a tall box, a wide box, a large square box). The model's job isn't to predict a box from scratch, but rather to predict small *adjustments* to the closest matching anchor box.\n",
    "\n",
    "Our task is to generate the full set of anchor boxes for every grid cell across every image in our batch.\n",
    "\n",
    "## **Your Task**\n",
    "\n",
    "Write a function `generate_anchor_grids(scaled_grids, anchor_boxes)` that takes:\n",
    "\n",
    "1.  `scaled_grids`: The output from our previous problem—a tensor of pixel coordinates for the grid centers, with shape `(batch_size, grid_size, grid_size, 2)`.\n",
    "2.  `anchor_boxes`: A 2D tensor of shape `(num_anchors, 2)`, where each row is a `[width, height]` pair for a pre-defined anchor.\n",
    "\n",
    "The function should return a tensor of shape `(batch_size, grid_size, grid_size, num_anchors, 4)`. This final tensor represents the specific bounding boxes (in `[x_min, y_min, x_max, y_max]` format) for every anchor at every grid location.\n",
    "\n",
    "**Calculation Logic**:\n",
    "For each grid center `(cx, cy)` from `scaled_grids` and each anchor size `(w, h)` from `anchor_boxes`:\n",
    "* `x_min = cx - w / 2`\n",
    "* `y_min = cy - h / 2`\n",
    "* `x_max = cx + w / 2`\n",
    "* `y_max = cy + h / 2`\n",
    "\n",
    "**Core Challenge**: This is another broadcasting puzzle, but with more dimensions. You'll need to expand both `scaled_grids` and `anchor_boxes` so you can perform the `center +/- size/2` calculation. After calculating the `min` and `max` coordinates, you will need to combine them to form the final `(..., 4)` dimension.\n",
    "\n",
    "This is the most complex problem yet, but it uses the exact same principles you've already mastered. Good luck!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2ae967c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def generate_anchor_grids(scaled_grids, anchor_boxes):\n",
    "    ## step 1: add axis to scaled grids\n",
    "    reshaped_scaled_grids = scaled_grids[:,:,:,tf.newaxis,:]\n",
    "    ## step 2: add axis to anchor_boxes\n",
    "    reshaped_anchor_boxes = anchor_boxes[tf.newaxis,tf.newaxis,tf.newaxis,:,:]\n",
    "    ## step 3: calculate min values\n",
    "    min_values = reshaped_scaled_grids - reshaped_anchor_boxes/2\n",
    "    max_values = reshaped_scaled_grids + reshaped_anchor_boxes/2\n",
    "    ## step 4: calculate anchor grid\n",
    "    anchor_grid = tf.concat([min_values,max_values],axis=-1)\n",
    "    return anchor_grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1e62ee31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 2, 2, 3, 4), dtype=float32, numpy=\n",
       "array([[[[[ 95.,  95., 105., 105.],\n",
       "          [ 90.,  95., 110., 105.],\n",
       "          [ 95.,  90., 105., 110.]],\n",
       "\n",
       "         [[295.,  95., 305., 105.],\n",
       "          [290.,  95., 310., 105.],\n",
       "          [295.,  90., 305., 110.]]],\n",
       "\n",
       "\n",
       "        [[[ 95., 295., 105., 305.],\n",
       "          [ 90., 295., 110., 305.],\n",
       "          [ 95., 290., 105., 310.]],\n",
       "\n",
       "         [[295., 295., 305., 305.],\n",
       "          [290., 295., 310., 305.],\n",
       "          [295., 290., 305., 310.]]]]], dtype=float32)>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Shape: (batch_size=1, grid_size=2, grid_size=2, 2)\n",
    "## i.e. one 2x2 grid => 4 grid centers. \n",
    "scaled_grids = tf.constant(\n",
    "    [[[[100., 100.], [300., 100.]],\n",
    "      [[100., 300.], [300., 300.]]]],\n",
    "    dtype=tf.float32\n",
    ")\n",
    "\n",
    "# Shape: (num_anchors=3, 2)\n",
    "# i.e. 3 anchors defined with their width and height.\n",
    "anchor_boxes = tf.constant(\n",
    "    [[10., 10.],  # Anchor 1: width=10, height=10\n",
    "     [20., 10.],  # Anchor 2: width=20, height=10\n",
    "     [10., 20.]], # Anchor 3: width=10, height=20\n",
    "    dtype=tf.float32\n",
    ")\n",
    "\n",
    "anchor_grid = generate_anchor_grids(scaled_grids=scaled_grids,anchor_boxes=anchor_boxes)\n",
    "anchor_grid\n",
    "  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0791741e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([ 90.  95. 110. 105.], shape=(4,), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "print(anchor_grid[0, 0, 0, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef41efae",
   "metadata": {},
   "source": [
    "# Problem #5: Calculating Intersection over Union (IoU)\n",
    "\n",
    "## **Context**\n",
    "\n",
    "Intersection over Union (IoU) is a number from 0 to 1 that measures how much two bounding boxes overlap. It's the ratio of the area of their intersection to the area of their union.\n",
    "\n",
    "IoU is critical for two main reasons:\n",
    "\n",
    "1.  **During Training**: We use IoU to match our generated anchor boxes to the ground truth object boxes. An anchor with a high IoU to a ground truth box is considered a \"positive\" example responsible for predicting that object.\n",
    "2.  **During Inference**: We use IoU in a process called Non-Max Suppression (NMS) to eliminate redundant, overlapping predictions for the same object.\n",
    "\n",
    "Your task is to implement a fully vectorized function that calculates the pairwise IoU for two sets of boxes.\n",
    "\n",
    "## **Your Task**\n",
    "\n",
    "Write a function `calculate_iou(boxes1, boxes2)` that takes:\n",
    "\n",
    "1.  `boxes1`: A tensor of shape `(N, 4)` representing N bounding boxes.\n",
    "2.  `boxes2`: A tensor of shape `(M, 4)` representing M bounding boxes.\n",
    "\n",
    "<!-- end list -->\n",
    "\n",
    "  * The box format for both is `[x_min, y_min, x_max, y_max]`.\n",
    "\n",
    "The function should return a 2D tensor of shape `(N, M)`, where `output[i, j]` is the IoU score between `boxes1[i]` and `boxes2[j]`.\n",
    "\n",
    "## **Calculation Logic**\n",
    "\n",
    "This is a multi-step calculation that will require broadcasting to compare every box from `boxes1` with every box from `boxes2`.\n",
    "\n",
    "1.  **Expand Dims for Broadcasting**: Reshape `boxes1` to `(N, 1, 4)` and `boxes2` to `(1, M, 4)`.\n",
    "2.  **Find Intersection Coordinates**:\n",
    "      * The top-left corner of the intersection is `(max(box1_x_min, box2_x_min), max(box1_y_min, box2_y_min))`. Use `tf.maximum`.\n",
    "      * The bottom-right corner is `(min(box1_x_max, box2_x_max), min(box1_y_max, box2_y_max))`. Use `tf.minimum`.\n",
    "3.  **Calculate Intersection Area**:\n",
    "      * Calculate the width and height of the intersection.\n",
    "      * **Crucial Edge Case**: If the boxes don't overlap, the width or height can be negative. You must clip them at 0 (`tf.maximum(width, 0)`). The area is then `width * height`.\n",
    "4.  **Calculate Union Area**:\n",
    "      * Calculate the area of all boxes in `boxes1` and `boxes2`. Area is `(x_max - x_min) * (y_max - y_min)`.\n",
    "      * The union area is `area1 + area2 - intersection_area`.\n",
    "5.  **Calculate IoU**:\n",
    "      * `IoU = intersection_area / union_area`.\n",
    "      * **Crucial Edge Case**: To avoid dividing by zero if the union area is 0, add a tiny number (epsilon, e.g., `1e-7`) to the denominator.\n",
    "\n",
    "-----\n",
    "\n",
    "### Test Data\n",
    "\n",
    "```python\n",
    "# boxes1 has 2 boxes\n",
    "boxes1 = tf.constant([[0, 0, 10, 10],   # Box A\n",
    "                       [15, 15, 25, 25]], # Box B\n",
    "                      dtype=tf.float32)\n",
    "\n",
    "# boxes2 has 3 boxes\n",
    "boxes2 = tf.constant([[5, 5, 15, 15],     # Box C (overlaps A)\n",
    "                       [0, 0, 10, 10],     # Box D (identical to A)\n",
    "                       [30, 30, 40, 40]],  # Box E (no overlap)\n",
    "                      dtype=tf.float32)\n",
    "```\n",
    "\n",
    "## **Expected Output Shape**: `(2, 3)`\n",
    "\n",
    "## **Sanity Check**\n",
    "\n",
    "  * **IoU of Box A and Box D**: They are identical. The intersection is the area of the box (100), and the union is also the area of the box (100). The IoU should be `1.0`.\n",
    "  * **IoU of Box B and Box E**: They have no overlap. The intersection area is 0. The IoU should be `0.0`.\n",
    "\n",
    "This one brings everything together: broadcasting, element-wise math, slicing, and handling edge cases. Good luck\\!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9e0cadd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_iou(boxes1, boxes2):\n",
    "    # step 1 expand dimensions\n",
    "    reshaped_boxes1 = boxes1[:, tf.newaxis, :]\n",
    "    reshaped_boxes2 = boxes2[tf.newaxis, :, :]\n",
    "\n",
    "    # step 2 calculate top left corner of intersection\n",
    "    # top_left_x = tf.maximum(reshaped_boxes1[:, :, 0], reshaped_boxes2[:, :, 0])\n",
    "    # top_left_y = tf.maximum(reshaped_boxes1[:, :, 1], reshaped_boxes2[:, :, 1])\n",
    "    # top_left = tf.stack([top_left_x, top_left_y], axis=-1)\n",
    "    top_left = tf.maximum(reshaped_boxes1[:, :, 0:2],reshaped_boxes2[:, :, 0:2])\n",
    "    \n",
    "    # step 3 calculate bottom right corner of intersection\n",
    "    # bottom_right_x = tf.minimum(\n",
    "    #     reshaped_boxes1[:, :, 2], reshaped_boxes2[:, :, 2])\n",
    "    # bottom_right_y = tf.minimum(\n",
    "    #     reshaped_boxes1[:, :, 3], reshaped_boxes2[:, :, 3])\n",
    "    # bottom_right = tf.stack([bottom_right_x, bottom_right_y], axis=-1)\n",
    "    bottom_right = tf.minimum(reshaped_boxes1[:, :, 2:],reshaped_boxes2[:, :, 2:])\n",
    "\n",
    "    # step 4 calculate intersection area width\n",
    "    intersection_width = tf.maximum(\n",
    "        (bottom_right[:, :, 0] - top_left[:, :, 0]), 0)\n",
    "\n",
    "    # step 5 calculate intersection height\n",
    "    intersection_height = tf.maximum(\n",
    "        (bottom_right[:, :, 1] - top_left[:, :, 1]), 0)\n",
    "\n",
    "    # step 6 calculate intersection area\n",
    "    intersection_area = intersection_width * intersection_height\n",
    "\n",
    "    # step 7 calculate intersection union\n",
    "    boxes1_area = (reshaped_boxes1[:, :, 2] - reshaped_boxes1[:, :, 0]) * \\\n",
    "        (reshaped_boxes1[:, :, 3] - reshaped_boxes1[:, :, 1])\n",
    "        \n",
    "    boxes2_area = (reshaped_boxes2[:, :, 2] - reshaped_boxes2[:, :, 0]) * \\\n",
    "        (reshaped_boxes2[:, :, 3] - reshaped_boxes2[:, :, 1])        \n",
    "    \n",
    "    union_area = boxes1_area + boxes2_area - intersection_area\n",
    "\n",
    "    ## step 8 calculate iou\n",
    "    epsilon = 1e-7 ## adding epsilon to ensure that denominator is always non-zero.\n",
    "    iou = intersection_area / (union_area + epsilon)\n",
    "\n",
    "    return iou"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a57157c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 3), dtype=float32, numpy=\n",
       "array([[0.14285715, 1.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        ]], dtype=float32)>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# boxes1 has 2 boxes\n",
    "boxes1 = tf.constant([[0, 0, 10, 10],   # Box A\n",
    "                       [15, 15, 25, 25]], # Box B\n",
    "                      dtype=tf.float32)\n",
    "\n",
    "# boxes2 has 3 boxes\n",
    "boxes2 = tf.constant([[5, 5, 15, 15],     # Box C (overlaps A)\n",
    "                       [0, 0, 10, 10],     # Box D (identical to A)\n",
    "                       [30, 30, 40, 40]],  # Box E (no overlap)\n",
    "                      dtype=tf.float32)\n",
    "\n",
    "ious= calculate_iou(boxes1=boxes1,boxes2=boxes2)\n",
    "ious"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e0e6d6a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 2, 3)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 1, 3), dtype=int32, numpy=\n",
       "array([[[3, 3, 3]],\n",
       "\n",
       "       [[5, 5, 5]]], dtype=int32)>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = tf.constant([[[1, 1, 1], [2, 2, 2]],\n",
    "                 [[3, 3, 3], [4, 4, 4]],\n",
    "                 [[5, 5, 5], [6, 6, 6]]])\n",
    "\n",
    "print(t.shape)\n",
    "tf.slice(t, [1, 0, 0], [1, 1, 3])  # [[[3, 3, 3]]]\n",
    "tf.slice(t, [1, 0, 0], [1, 2, 3])  # [[[3, 3, 3],\n",
    "                                   #   [4, 4, 4]]]\n",
    "tf.slice(t, [1, 0, 0], [2, 1, 3])  # [[[3, 3, 3]],\n",
    "                                   #  [[5, 5, 5]]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93c0e096",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
