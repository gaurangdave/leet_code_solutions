{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "adb78719",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-07 14:45:17.305593: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4e5b9392",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n"
     ]
    }
   ],
   "source": [
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cf3dccf",
   "metadata": {},
   "source": [
    "# Problem #1: Generating a Normalized Coordinate Grid\n",
    "**Source** : Gemini\n",
    "\n",
    "**Context**\n",
    "In many computer vision tasks, particularly in object detection (e.g., YOLO, SSD), we divide an image into a grid. Each cell in this grid is responsible for predicting objects located within it. To do this, the model needs to know the location of each grid cell. Your task is to generate a tensor that contains the normalized (x, y) coordinates of the center of each cell.\n",
    "\n",
    "**Your Task**\n",
    "Write a Python function generate_normalized_grid(grid_size) that takes an integer grid_size and returns a TensorFlow tensor with the following properties:\n",
    "\n",
    "**Shape**: (grid_size, grid_size, 2)\n",
    "\n",
    "**Data Type**: tf.float32\n",
    "\n",
    "**Content**: The tensor should represent a grid where the last dimension [..., 0] holds the normalized x-coordinates and [..., 1] holds the normalized y-coordinates. The coordinates must be normalized to the range [0.0, 1.0).\n",
    "\n",
    "**Normalization Logic**: For a grid of size N, the center of the cell at (row, col) has coordinates ((col + 0.5) / N, (row + 0.5) / N).\n",
    "\n",
    "**Example**\n",
    "If grid_size = 2, the expected output tensor is:\n",
    "```python\n",
    "<tf.Tensor: shape=(2, 2, 2), dtype=float32, numpy=\n",
    "[[[0.25, 0.25],  # Cell at (row=0, col=0) -> (x=0.25, y=0.25)\n",
    "  [0.75, 0.25]], # Cell at (row=0, col=1) -> (x=0.75, y=0.25)\n",
    "\n",
    " [[0.25, 0.75],  # Cell at (row=1, col=0) -> (x=0.25, y=0.75)\n",
    "  [0.75, 0.75]]]># Cell at (row=1, col=1) -> (x=0.75, y=0.75)\n",
    "```\n",
    "Notice how the x-coordinate increases along the columns and the y-coordinate increases along the rows.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5c3a040",
   "metadata": {},
   "source": [
    "## Thoughts\n",
    "* So here we need a vectorized solution that creates a tensor whose values depend on its indices.\n",
    "* I think it would help to initialize the grid cells with index values. \n",
    "* We can initialize the grid with zeroes and then use `scatter_nd_update` to update the row cells and column cells.\n",
    "\n",
    "### Update\n",
    "* Found a simpler way to do this, created 2 colums using tf.range and tf.repeat and combined it to create a tensor grid where each cell value represented its coordinate value.\n",
    "* After that calculation was as simple as broadcasting addition and division \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e26d845",
   "metadata": {},
   "source": [
    "## Solution 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0a06aa7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def generate_normalized_grid(grid_size = 2):\n",
    "    ## step 1 - get the grid indices range\n",
    "    grid_range = tf.range(grid_size, dtype=tf.float32)\n",
    "    ## create column 0 for the grid - this column represents the x-coordinate of each grid cell\n",
    "    ## value indices of this column would be 0,0,1,1 for grid_size 2\n",
    "    col_0 = tf.reshape(tf.repeat(grid_range,repeats=grid_size), shape=(grid_size,grid_size,1))\n",
    "    ## create column 1 for the grid - this column represents y-coordinate of each cell\n",
    "    col_1 = tf.reshape(tf.repeat([grid_range],repeats=grid_size,axis=0),shape=(grid_size,grid_size,1))\n",
    "    ## concatenate to form our grid\n",
    "    ## currently each grid cell represents it index value in float. \n",
    "    grid = tf.concat(values = [col_1,col_0], axis = 2)\n",
    "    ## calculate the grid cell center. \n",
    "    coordinate_grid = (grid + 0.5)/grid_size\n",
    "    return coordinate_grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b46b7212",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1759873521.938794   75287 gpu_device.cc:2020] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 6053 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 2080 SUPER, pci bus id: 0000:2e:00.0, compute capability: 7.5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 2, 2), dtype=float32, numpy=\n",
       "array([[[0.25, 0.25],\n",
       "        [0.75, 0.25]],\n",
       "\n",
       "       [[0.25, 0.75],\n",
       "        [0.75, 0.75]]], dtype=float32)>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_normalized_grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a1de84a",
   "metadata": {},
   "source": [
    "## Solution 2 - using tf.meshgrid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d734b08f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def generate_grid_cooridinates(grid_size = 2):\n",
    "    # 1. Create a 1D vector for x indices: [0, 1, 2, ...]\n",
    "    coorinate_range = tf.range(grid_size, dtype=tf.float32)\n",
    "    grid_X,grid_Y = tf.meshgrid(coorinate_range,coorinate_range)\n",
    "    coordinate_grid = tf.stack(values=[grid_X,grid_Y], axis=2)\n",
    "    return coordinate_grid\n",
    "    \n",
    "def generate_normalized_grid(grid_size = 2):\n",
    "    coordinate_grid = generate_grid_cooridinates(grid_size=grid_size)\n",
    "    normalized_grid = (coordinate_grid + 0.5) / grid_size\n",
    "    return normalized_grid\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6cc9b977",
   "metadata": {},
   "outputs": [],
   "source": [
    "normalized_grid = generate_normalized_grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b50a6684",
   "metadata": {},
   "source": [
    "# Problem #2 : Scaling the Grid to Image Coordinates\n",
    "**Source**: Gemini\n",
    "\n",
    "**Context**\n",
    "In our object detection project, the normalized grid you just created is a generic, resolution-independent representation. However, to actually use it with a specific image, we need to convert those [0.0, 1.0) coordinates into actual pixel coordinates. For example, the center of the top-left cell in a 13x13 grid might be (0.038, 0.038) in normalized space, but on a 416x416 pixel image, that corresponds to pixel (16, 16).\n",
    "\n",
    "**Your Task**\n",
    "Write a Python function `scale_grid_to_pixels(normalized_grid, image_shape)` that takes two arguments:\n",
    "\n",
    "**normalized_grid**: The output tensor from our previous problem, with shape (grid_size, grid_size, 2).\n",
    "\n",
    "**image_shape**: A 1D TensorFlow tensor or a Python tuple/list of two integers, **`[height, width]`**.\n",
    "\n",
    "The function should return a new tensor with the same shape as normalized_grid, but where the (x, y) coordinates have been scaled to the pixel space of the image.\n",
    "\n",
    "**Scaling Logic**:\n",
    "\n",
    "`pixel_x = normalized_x * width`\n",
    "\n",
    "`pixel_y = normalized_y * height`\n",
    "\n",
    "**Example**:\n",
    "Given the normalized_grid for grid_size = 2:\n",
    "```\n",
    "[[[0.25, 0.25], [0.75, 0.25]],\n",
    " [[0.25, 0.75], [0.75, 0.75]]]\n",
    "```\n",
    "And an image_shape of [416, 416], the expected output is:\n",
    "```\n",
    "<tf.Tensor: shape=(2, 2, 2), dtype=float32, numpy=\n",
    "[[[104., 104.],  # (0.25*416, 0.25*416)\n",
    "  [312., 104.]], # (0.75*416, 0.25*416)\n",
    "\n",
    " [[104., 312.],  # (0.25*416, 0.75*416)\n",
    "  [312., 312.]]]># (0.75*416, 0.75*416)\n",
    "```\n",
    "**Important**: Note the order. The image_shape is (height, width), but our coordinate grid is (x, y). Your solution will need to handle this correctly."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "285f5633",
   "metadata": {},
   "source": [
    "## Thoughts\n",
    "* First impression of this problem is that this is straight forward, just a simple multiplication. Lets try that and see"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e69a4055",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def scale_grid_to_pixels(normalized_grid, image_shape):\n",
    "    ## cast to float32\n",
    "    img_shape_float = tf.cast(image_shape, dtype=tf.float32)\n",
    "    ## reorder the image shape colums so that we multiply normalized_x with width and normalized_y with height\n",
    "    reordered_column = tf.gather(params=img_shape_float, indices=[1,0],axis=0)\n",
    "    scaled_grid = tf.multiply(normalized_grid, reordered_column)\n",
    "    return scaled_grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "35a0d2fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 2, 2), dtype=float32, numpy=\n",
       "array([[[104., 104.],\n",
       "        [312., 104.]],\n",
       "\n",
       "       [[104., 312.],\n",
       "        [312., 312.]]], dtype=float32)>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_shape = tf.constant(value=[416,416])\n",
    "scale_grid_to_pixels(normalized_grid=normalized_grid,image_shape=image_shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e439e0b",
   "metadata": {},
   "source": [
    "# Problem #3: Batch-Scaling Grids for Multiple Images\n",
    "\n",
    "**Context**\n",
    "To train a neural network efficiently, we process multiple images at once in a \"batch\". Our grid scaling logic needs to support this. We'll have one common normalized_grid, but a list of different image shapesâ€”one for each image in the batch. Your task is to perform the scaling operation for the entire batch in a single, vectorized call.\n",
    "\n",
    "**Your Task**\n",
    "Write a function batch_scale_grids(normalized_grid, batch_image_shapes) that takes:\n",
    "\n",
    "`normalized_grid: The (grid_size, grid_size, 2) tensor from Problem #1.`\n",
    "\n",
    "`batch_image_shapes: A 2D tensor of shape (batch_size, 2), where each row is an [height, width] pair.`\n",
    "\n",
    "The function should return a single tensor of shape (batch_size, grid_size, grid_size, 2) containing the scaled grid for each image.\n",
    "\n",
    "**Example**\n",
    "Given normalized_grid (for grid_size=2) and batch_image_shapes:\n",
    "\n",
    "```python\n",
    "# A batch of 2 images with different shapes\n",
    "batch_image_shapes = tf.constant([[416, 416],  # Image 1 is 416x416\n",
    "                                  [800, 600]], # Image 2 is 800x600 (WxH) -> No, (HxW)\n",
    "                                 dtype=tf.int32)\n",
    "```\n",
    "The goal is to multiply the single (2, 2, 2) normalized grid with the (2, 2) batch of shapes to produce a (2, 2, 2, 2) - (batch_size, grid_size, grid_size, 2) output tensor."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7509d2b9",
   "metadata": {},
   "source": [
    "## Thoughts\n",
    "* This is interesting, the shape of both these tensors are different, so direct tensor multiplication won't work. \n",
    "* We can try and use `tf.newaxis` to add axis to normalized grid and then do a tf.reshape to get the desired output. \n",
    "* We'll also need to reorder elements of batch image shape like we did before. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "edab5da3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_normalized_grid(normalized_grid, batch_image_shapes):\n",
    "    batch_image_shapes_float = tf.cast(batch_image_shapes, dtype=tf.float32)\n",
    "    ## reorder the values\n",
    "    batch_image_shapes_float_reordered = tf.reverse(batch_image_shapes_float, axis=[-1])\n",
    "    ## add additional axis\n",
    "    batch_image_shapes_float_reordered = batch_image_shapes_float_reordered[:,tf.newaxis,tf.newaxis,:]\n",
    "    normalized_grid_expanded = normalized_grid[tf.newaxis,:]\n",
    "    ## this will give us batch_image_shape as (batch_size,1,1,2) and normalized grid as (1,grid_size,grid_size,2)\n",
    "    ## multiplying these two will give us (batch_size, grid_size,grid_size,2)\n",
    "    normalized_grid = tf.multiply(normalized_grid_expanded,batch_image_shapes_float_reordered)\n",
    "    return normalized_grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "c0debd92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 2, 2, 2), dtype=float32, numpy=\n",
       "array([[[[104., 104.],\n",
       "         [312., 104.]],\n",
       "\n",
       "        [[104., 312.],\n",
       "         [312., 312.]]],\n",
       "\n",
       "\n",
       "       [[[150., 200.],\n",
       "         [450., 200.]],\n",
       "\n",
       "        [[150., 600.],\n",
       "         [450., 600.]]]], dtype=float32)>"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_image_shapes = tf.constant([[416, 416],  # Image 1 is 416x416\n",
    "                                  [800, 600]], # Image 2 is 800x600 (WxH) -> No, (HxW)\n",
    "                                 dtype=tf.int32)\n",
    "\n",
    "temp = batch_normalized_grid(normalized_grid=normalized_grid, batch_image_shapes=batch_image_shapes)\n",
    "temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "8c0b5424",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original tensor shape: (2, 3)\n",
      "Expanded tensor shape (axis=1): (2, 1, 3)\n"
     ]
    }
   ],
   "source": [
    "tensor = tf.constant([[1, 2, 3], [4, 5, 6]])\n",
    "print(\"Original tensor shape:\", tensor.shape)\n",
    "\n",
    "# Add a new axis at index 1 (between existing dimensions)\n",
    "expanded_tensor = tf.expand_dims(tensor, axis=1)\n",
    "print(\"Expanded tensor shape (axis=1):\", expanded_tensor.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "82e366fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 1, 3), dtype=int32, numpy=\n",
       "array([[[1, 2, 3]],\n",
       "\n",
       "       [[4, 5, 6]]], dtype=int32)>"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "expanded_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "4d6d83e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original tensor shape: (2, 3)\n",
      "Expanded tensor shape (tf.newaxis in middle): (2, 1, 1, 3)\n"
     ]
    }
   ],
   "source": [
    "tensor = tf.constant([[1, 2, 3], [4, 5, 6]])\n",
    "print(\"Original tensor shape:\", tensor.shape)\n",
    "\n",
    "# Add a new axis at index 1 (between existing dimensions)\n",
    "# The ellipsis (...) represents all other existing dimensions\n",
    "expanded_tensor = tensor[:, tf.newaxis,tf.newaxis, :]\n",
    "print(\"Expanded tensor shape (tf.newaxis in middle):\", expanded_tensor.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a19d668b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
